{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll combine two different works: we'll use the geometry of word embeddings used Kozlowski et al. (2019), \"[The Geometry of Culture: Analyzing the Meanings of Class through Word Embeddings](https://journals.sagepub.com/doi/full/10.1177/0003122419877135)\" to explore axes of cultural meaning in So and Rowland (2020), \"[Race and Distant Reading](https://www.mlajournals.org/doi/abs/10.1632/pmla.2020.135.1.59)\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import datapath\n",
    "import numpy as np\n",
    "from pandas import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load up two sets of pre-trained embeddings.  `fiction.embeddings.txt` is trained on 296 works of contemporary fiction (published between 1924 and 2020); `bbip.embeddings.txt` is trained on 45 works written by Black writers, selected from the [Black Book Interactive Project](https://bbip.ku.edu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiction_vectors = KeyedVectors.load_word2vec_format(\"../data/fiction.embeddings.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbip_vectors = KeyedVectors.load_word2vec_format(\"../data/bbip.embeddings.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(word, vectors):\n",
    "    return vectors[word]/LA.norm(vectors[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_affluence_vector(vectors):\n",
    "    \n",
    "    \"\"\" affluence word pairs from Kozlowski et al. 2019) \"\"\"\n",
    "    \n",
    "    vecs=[]\n",
    "    vecs.append(get_vector(\"rich\", vectors)-get_vector(\"poor\", vectors))\n",
    "    vecs.append(get_vector(\"richer\", vectors)-get_vector(\"poorer\", vectors))\n",
    "    vecs.append(get_vector(\"richest\", vectors)-get_vector(\"poorest\", vectors))\n",
    "    vecs.append(get_vector(\"affluence\", vectors)-get_vector(\"poverty\", vectors))\n",
    "    vecs.append(get_vector(\"affluent\", vectors)-get_vector(\"destitute\", vectors))\n",
    "    vecs.append(get_vector(\"wealthy\", vectors)-get_vector(\"impoverished\", vectors))\n",
    "    vecs.append(get_vector(\"costly\", vectors)-get_vector(\"economical\", vectors))\n",
    "    vecs.append(get_vector(\"expensive\", vectors)-get_vector(\"inexpensive\", vectors))\n",
    "    vecs.append(get_vector(\"exquisite\", vectors)-get_vector(\"ruined\", vectors))\n",
    "    vecs.append(get_vector(\"invaluable\", vectors)-get_vector(\"cheap\", vectors))\n",
    "    vecs.append(get_vector(\"lavish\", vectors)-get_vector(\"economical\", vectors))\n",
    "    vecs.append(get_vector(\"luxurious\", vectors)-get_vector(\"threadbare\", vectors))\n",
    "    vecs.append(get_vector(\"luxury\", vectors)-get_vector(\"cheap\", vectors))\n",
    "    vecs.append(get_vector(\"plush\", vectors)-get_vector(\"threadbare\", vectors))\n",
    "    vecs.append(get_vector(\"precious\", vectors)-get_vector(\"cheap\", vectors))\n",
    "    vecs.append(get_vector(\"priceless\", vectors)-get_vector(\"worthless\", vectors))\n",
    "    vecs.append(get_vector(\"successful\", vectors)-get_vector(\"unsuccessful\", vectors))\n",
    "    vecs.append(get_vector(\"sumptuous\", vectors)-get_vector(\"plain\", vectors))\n",
    "    vecs.append(get_vector(\"rich\", vectors)-get_vector(\"penniless\", vectors))\n",
    "    vecs.append(get_vector(\"posh\", vectors)-get_vector(\"plain\", vectors))\n",
    "\n",
    "    # commenting out word pairs from Kozlowski et al. 2019 not in the vocabulary here \n",
    "#     vecs.append(get_vector(\"advantaged\", vectors)-get_vector(\"needy\", vectors))\n",
    "#     vecs.append(get_vector(\"exorbitant\", vectors)-get_vector(\"impecunious\", vectors))\n",
    "#     vecs.append(get_vector(\"extravagant\", vectors)-get_vector(\"necessitous\", vectors))\n",
    "#     vecs.append(get_vector(\"flush\", vectors)-get_vector(\"skint\", vectors))\n",
    "#     vecs.append(get_vector(\"luxuriant\", vectors)-get_vector(\"penurious\", vectors))\n",
    "#     vecs.append(get_vector(\"moneyed\", vectors)-get_vector(\"unmonied\", vectors))\n",
    "#     vecs.append(get_vector(\"opulent\", vectors)-get_vector(\"indigent\", vectors))\n",
    "#     vecs.append(get_vector(\"luxuriant\", vectors)-get_vector(\"penurious\", vectors))\n",
    "#     vecs.append(get_vector(\"privileged\", vectors)-get_vector(\"underprivileged\", vectors))\n",
    "#     vecs.append(get_vector(\"propertied\", vectors)-get_vector(\"bankrupt\", vectors))\n",
    "#     vecs.append(get_vector(\"prosperous\", vectors)-get_vector(\"unprosperous\", vectors))\n",
    "#     vecs.append(get_vector(\"developed\", vectors)-get_vector(\"underdeveloped\", vectors))\n",
    "#     vecs.append(get_vector(\"solvency\", vectors)-get_vector(\"insolvency\", vectors))\n",
    "#     vecs.append(get_vector(\"swanky\", vectors)-get_vector(\"basic\", vectors))\n",
    "#     vecs.append(get_vector(\"thriving\", vectors)-get_vector(\"disadvantaged\", vectors))\n",
    "#     vecs.append(get_vector(\"upscale\", vectors)-get_vector(\"squalid\", vectors))\n",
    "#     vecs.append(get_vector(\"valuable\", vectors)-get_vector(\"valueless\", vectors))\n",
    "#     vecs.append(get_vector(\"classy\", vectors)-get_vector(\"beggarly\", vectors))\n",
    "#     vecs.append(get_vector(\"ritzy\", vectors)-get_vector(\"ramshackle\", vectors))\n",
    "#     vecs.append(get_vector(\"opulence\", vectors)-get_vector(\"indigence\", vectors))\n",
    "#     vecs.append(get_vector(\"solvent\", vectors)-get_vector(\"insolvent\", vectors))\n",
    "#     vecs.append(get_vector(\"moneyed\", vectors)-get_vector(\"moneyless\", vectors))\n",
    "#     vecs.append(get_vector(\"affluence\", vectors)-get_vector(\"penury\", vectors))\n",
    "#     vecs.append(get_vector(\"opulence\", vectors)-get_vector(\"indigence\", vectors))\n",
    "\n",
    "    return np.mean(vecs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gender_vector(vectors):\n",
    "    \n",
    "    \"\"\" gender word pairs from Kozlowski et al. 2019) \"\"\"\n",
    "\n",
    "    vecs=[]\n",
    "    vecs.append(get_vector(\"man\", vectors)-get_vector(\"woman\", vectors))\n",
    "    vecs.append(get_vector(\"men\", vectors)-get_vector(\"women\", vectors))\n",
    "    vecs.append(get_vector(\"he\", vectors)-get_vector(\"she\", vectors))\n",
    "    vecs.append(get_vector(\"him\", vectors)-get_vector(\"her\", vectors))\n",
    "    vecs.append(get_vector(\"his\", vectors)-get_vector(\"her\", vectors))\n",
    "    vecs.append(get_vector(\"his\", vectors)-get_vector(\"hers\", vectors))\n",
    "    vecs.append(get_vector(\"boy\", vectors)-get_vector(\"girl\", vectors))\n",
    "    vecs.append(get_vector(\"boys\", vectors)-get_vector(\"girls\", vectors))\n",
    "    vecs.append(get_vector(\"male\", vectors)-get_vector(\"female\", vectors))\n",
    "\n",
    "    # commenting out word pairs from Kozlowski et al. 2019 not in the vocabulary here \n",
    "    #     vecs.append(get_vector(\"masculine\", vectors)-get_vector(\"feminine\", vectors))\n",
    "\n",
    "    return np.mean(vecs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_race_vector(vectors):\n",
    "    \n",
    "    \"\"\" race word pairs from Kozlowski et al. 2019) \"\"\"\n",
    "    \n",
    "    vecs=[]\n",
    "    vecs.append(get_vector(\"black\", vectors)-get_vector(\"white\", vectors))\n",
    "    vecs.append(get_vector(\"blacks\", vectors)-get_vector(\"whites\", vectors))\n",
    "    vecs.append(get_vector(\"african\", vectors)-get_vector(\"european\", vectors))\n",
    "    vecs.append(get_vector(\"african\", vectors)-get_vector(\"caucasian\", vectors))\n",
    "    \n",
    "    # commenting out word pairs from Kozlowski et al. 2019 not in the vocabulary here \n",
    "    #     vecs.append(get_vector(\"afro\", vectors)-get_vector(\"anglo\", vectors))\n",
    "    \n",
    "    return np.mean(vecs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_vector(vectors):\n",
    "    \n",
    "    \"\"\" let's add a sentiment dimension of our own \"\"\"\n",
    "        \n",
    "    vecs=[]\n",
    "    vecs.append(get_vector(\"good\", vectors)-get_vector(\"bad\", vectors))\n",
    "    vecs.append(get_vector(\"better\", vectors)-get_vector(\"worse\", vectors))\n",
    "    vecs.append(get_vector(\"best\", vectors)-get_vector(\"worst\", vectors))\n",
    "    vecs.append(get_vector(\"great\", vectors)-get_vector(\"terrible\", vectors))\n",
    "\n",
    "    return np.mean(vecs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(terms, vectors):\n",
    "    racial_vector=get_racial_vector(vectors)\n",
    "    affluence_vector=get_affluence_vector(vectors)\n",
    "    gender_vector=get_gender_vector(vectors)\n",
    "    sentiment_vector=get_sentiment_vector(vectors)\n",
    "    all_scores=[]\n",
    "    \n",
    "    for term in terms:\n",
    "        scores=[]\n",
    "        scores.append(term)\n",
    "        \n",
    "        scores.append(\"%.3f\" % vectors.cosine_similarities(racial_vector, [vectors[term]]))\n",
    "        scores.append(\"%.3f\" % vectors.cosine_similarities(affluence_vector, [vectors[term]]))\n",
    "        scores.append(\"%.3f\" % vectors.cosine_similarities(gender_vector, [vectors[term]]))\n",
    "        scores.append(\"%.3f\" % vectors.cosine_similarities(sentiment_vector, [vectors[term]]))\n",
    "\n",
    "        all_scores.append(scores)\n",
    "        \n",
    "    print(DataFrame(all_scores, columns=[\"term\", \"racial\", \"affluence\", \"gender\", \"sentiment\"]))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Kozlowski et al. (2019) point out, we can orient individual words along these cultural axes by seeing where they fall along the continuum defined by the endpoints.  Word vectors with higher positive cosine similarities have stronger orientation toward \"rich\", \"man\", \"black\" and \"positive\" (along the affluence, gender, race and sentiment axes, respectively); word vectors with higher negative cosine similarities have stronger orientation toward \"poor\", \"woman\", \"white\" and \"negative\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's check the orientation for the seed terms that partly define the axes to get a sense of the bounds for each of the word vectors we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms=[\"black\", \"white\", \"rich\", \"poor\", \"man\", \"woman\", \"good\", \"bad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_scores(terms, fiction_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_scores(terms, bbip_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, explore this semantic field by querying the orientation for other terms.  How does the affiliation of these terms with race, gender, affluence and sentiment accord with your expectations?  How could you use method to interrogate the representation of race, gender, and affluence in the datasets these works are drawn from?  Come up with a few terms of your own to query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms=[\"freedom\", \"slavery\", \"jazz\", \"opera\", \"family\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_scores(terms, fiction_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_scores(terms, bbip_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's take the terms identified in So and Rowland (2020) that contribute most to the misclassification of James Baldwin's *Giovanni's Room*.  In using the the geometry of word embeddings, we can examine *how* the words used in these texts being deployed.  How is this approach different from the methods used in So and Rowland (2020)?  How would you relate the conclusions you draw to their argument?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms=[\"absolutely\", \"very\", \"course\", \"appalled\", \"might\", \"white\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_scores(terms, fiction_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_scores(terms, bbip_vectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
